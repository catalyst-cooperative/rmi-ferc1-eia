{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e4e969-b223-42f1-b6ff-2708d59f6d55",
   "metadata": {},
   "source": [
    "# Add Overrides to Train FERC-EIA Connecter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664bb535-386b-4700-9b5f-5223e1f78159",
   "metadata": {},
   "source": [
    "This notebook is intended to help with adding overrides to the FERC-EIA connection csv. Adding new connections will fill in gaps and improve the program's ability to predict other matches. To adequately check each of the connections, we'll provide you with subsets of *three* different spreadsheets:\n",
    "\n",
    "1) **The current FERC-EIA connection:** to look for good, bad, and empty links between FERC and EIA records\n",
    "2) **The Master Unit List:** to confirm or disprove those connections\n",
    "3) **Depreciation data** from our previous work\n",
    "\n",
    "Downloading all the files at once will overwhelm excel, so we need to make edits in segments. This notebook will help you:\n",
    "\n",
    "1) **Download useful utility-based subsets of each table for review**\n",
    "2) **Update the old training data with new verified matches**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb51ca5-0953-47af-b2c9-8220f50dac27",
   "metadata": {},
   "source": [
    "## Edit Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b00eb6-e9dd-4be3-b148-7e78d747353d",
   "metadata": {},
   "source": [
    "It's time to choose what kind of data you'd like to wrangle first. We'll only download data from a specific subset of utilities and years if you say so. If you're not sure which PUDL IDs refer to which utilities, scroll down to section 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a34d5a7-2cfe-43a9-82ad-a12ed0c137d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be 'largest' or a list of pudl ids, ex: [1, 2, 3]\n",
    "specified_utilities = 'largest' \n",
    "\n",
    "# You can change this to any integer. This represents the number of utilities you'd like\n",
    "# to review (only applies when specified_utilities='largest').\n",
    "specified_amount = 2 \n",
    "\n",
    "# This can be 'all' or a list of any years within the FERC data, ex: [2006, 2007]\n",
    "# These are the years you would like to consider fixing AND the years you would like to \n",
    "# consider for detmining largest capacity (the latter is only used when `utilities = largest`.\n",
    "specified_years = [2018] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37379d51-bdcc-4c58-9258-2f9a1cec6d6d",
   "metadata": {},
   "source": [
    "## Verify Connections\n",
    "When you un-comment and run the following function, you'll find two new csvs in the output directory that were created based on the inputs specified above. Read the Instruction Manual to learn how to begin fixing/verifying the FERC-EIA connections.\n",
    "\n",
    "**Warning:** Running this funcion will REPLACE any override tools you currently have saved (unless you have changed their name). DO NOT run this function if you are in the middle of working on one of the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "cff3f2c9-8047-41a5-9705-27770013609b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting pudl ids for the top 2 largest utilities\n",
      "retreiving the ferc-eia connection for the given utilities\n",
      "retreiving the MUL for the given utilities\n",
      "outputing files to csv\n",
      "Saving dataframe to /Users/aesharpe/Desktop/Work/Catalyst_Coop/rmi-ferc1-eia/outputs/fix_FERC-EIA_overrides.xlsx\n",
      "Removing ferc_eia_util_subset from /Users/aesharpe/Desktop/Work/Catalyst_Coop/rmi-ferc1-eia/outputs/fix_FERC-EIA_overrides.xlsx\n",
      "Removing mul_util_subset from /Users/aesharpe/Desktop/Work/Catalyst_Coop/rmi-ferc1-eia/outputs/fix_FERC-EIA_overrides.xlsx\n",
      "CPU times: user 2min 29s, sys: 4.77 s, total: 2min 34s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# output_override_tools(\n",
    "#     check_connections, \n",
    "#     mul, \n",
    "#     utilities=specified_utilities,\n",
    "#     amount=specified_amount,\n",
    "#     years=specified_years\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d2122-cdd1-4556-b042-a84158b87a7e",
   "metadata": {},
   "source": [
    "## Upload Changes\n",
    "When you've finished editing the `ferc_eia_util_subset.csv` and want to add your changes to the official override csv, you can uncomment and run the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6ac6127-d271-40e6-9a45-63a98f43833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_override_overrides = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67cf36d9-f3b8-4427-b0b6-89ddaf39a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data_out.to_csv(training_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d91751c-6a55-43f3-92b0-990492257c22",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbac85a-d676-40f1-b9ef-52cc043080d9",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8709a4-db92-4e34-9251-263fd5f466e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f835e3-7283-4123-a1a0-f9d6770dfb02",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pudl\n",
    "import pudl.constants as pc\n",
    "import pudl.extract.ferc1\n",
    "import sqlalchemy as sa\n",
    "import logging\n",
    "import sys\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import scipy\n",
    "import statistics\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "import recordlinkage as rl\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bcf303f-2891-4354-9a6e-422b4ae9d6af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler(stream=sys.stdout)\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b43187cb-98c4-4044-ad97-362f3046f1d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")\n",
    "from pudl.output.ferc1 import *\n",
    "from pudl_rmi.connect_ferc1_to_eia import *\n",
    "from pudl_rmi.make_plant_parts_eia import *\n",
    "import pudl_rmi.connect_ferc1_to_eia\n",
    "pudl_settings = pudl.workspace.setup.get_defaults()\n",
    "pudl_engine = sa.create_engine(pudl_settings[\"pudl_db\"])\n",
    "ferc_engine = sa.create_engine(pudl_settings['ferc1_db'])\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa1c031-9a7d-4d00-b019-1469d14d7306",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "relevant_cols_ferc_eia = [\n",
    "    'record_id_ferc1',\n",
    "    'record_id_eia',\n",
    "    'true_gran',\n",
    "    'report_year',\n",
    "    'match_type',\n",
    "    'plant_part',\n",
    "    'ownership',\n",
    "    'utility_id_pudl_eia',\n",
    "    'utility_name_ferc1',\n",
    "    'plant_id_pudl_eia',\n",
    "    'unit_id_pudl',\n",
    "    'generator_id',\n",
    "    'plant_name_eia',\n",
    "    'plant_name_ferc1',\n",
    "    'technology_description',\n",
    "    'energy_source_code_1',\n",
    "    'net_generation_mwh_eia',\n",
    "    'net_generation_mwh_ferc1',\n",
    "    'capacity_mw_eia',\n",
    "    'capacity_mw_ferc1',\n",
    "    'total_fuel_cost_eia',\n",
    "    'total_fuel_cost_ferc1',\n",
    "    'installation_year',\n",
    "    'construction_year',\n",
    "]\n",
    "\n",
    "relevant_cols_mul = [\n",
    "    'record_id_eia',\n",
    "    'report_year',\n",
    "    'utility_id_pudl',\n",
    "    'utility_name_eia',\n",
    "    'fraction_owned',\n",
    "    'plant_id_eia',\n",
    "    'plant_name_new',\n",
    "    'generator_id',\n",
    "    'capacity_mw',\n",
    "    'capacity_factor',\n",
    "    'net_generation_mwh',\n",
    "    'installation_year',\n",
    "    'energy_source_code_1',\n",
    "    'technology_description',\n",
    "    'prime_mover_code',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2478274-c04f-40e4-b940-33def9e47000",
   "metadata": {},
   "source": [
    "## **Part 1:** Generate Override Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281260de-3fd4-48c5-85b6-8e3c3e8bc886",
   "metadata": {},
   "source": [
    "### 1.1 Get current FERC-EIA & MUL tables\n",
    "This is going to look a lot like the `connect_ferc1_to_eia.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f09b216-fec0-4312-adf0-119a20164651",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path_training = pathlib.Path().cwd().parent /'inputs'/'train_ferc1_to_eia.csv'\n",
    "file_path_mul = pathlib.Path().cwd().parent /'outputs' /'master_unit_list.pkl.gz'\n",
    "# pudl output object for ferc data\n",
    "pudl_out = pudl.output.pudltabl.PudlTabl(pudl_engine, ferc_engine, freq='AS',fill_fuel_cost=True,roll_fuel_cost=True,fill_net_gen=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62f0f2e0-c152-41cb-af2e-2d34c01c3e2a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the FERC1 tables.\n",
      "Reading the master unit list from /Users/aesharpe/Desktop/Work/Catalyst_Coop/rmi-ferc1-eia/outputs/master_unit_list.pkl.gz\n",
      "Generated 136066 all candidate features.\n",
      "Generated 528 training candidate features.\n",
      "We are about to test hyper parameters of the model while doing k-fold cross validation. This takes a few minutes....\n",
      "Scores from the best model hyperparameters:\n",
      "  F-Score:   0.78\n",
      "  Precision: 0.86\n",
      "  Accuracy:  0.53\n",
      "Fit and predict a model w/ the highest scoring hyperparameters.\n",
      "Get the top scoring match for each FERC1 steam record.\n",
      "Winning match stats:\n",
      "        matches vs ferc:      64.51%\n",
      "        best match v ferc:    56.05%\n",
      "        best match vs matches:86.90%\n",
      "        murk vs matches:      0.83%\n",
      "        ties vs matches:      7.79%\n",
      "Overridden records:       100.0%\n",
      "New best match v ferc:    56.37%\n"
     ]
    }
   ],
   "source": [
    "inputs = InputManager(file_path_training, file_path_mul, pudl_out)\n",
    "features_all = (Features(feature_type='all', inputs=inputs)\n",
    "                .get_features(clobber=False))\n",
    "features_train = (Features(feature_type='training', inputs=inputs)\n",
    "                  .get_features(clobber=False))\n",
    "tuner = ModelTuner(features_train, inputs.get_train_index(), n_splits=10)\n",
    "\n",
    "matcher = MatchManager(best=tuner.get_best_fit_model(), inputs=inputs)\n",
    "matches_best = matcher.get_best_matches(features_train, features_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdf0304b-20fb-4a20-ba2d-3d4d0e37bda6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage for matches during EIA working years:\n",
      "    Fuel type: 96.3%\n",
      "    Tech type: 41.5%\n",
      "\n",
      "Coverage for all steam table records during EIA working years:\n",
      "    EIA matches: 56.4\n",
      "\n",
      "Coverage for all small gen table records during EIA working years:\n",
      "    EIA matches: 40.9\n",
      "\n",
      "Coverage for all hydro table records during EIA working years:\n",
      "    EIA matches: 85.8\n",
      "\n",
      "Coverage for all pumped storage table records during EIA working years:\n",
      "    EIA matches: 45.7\n"
     ]
    }
   ],
   "source": [
    "connects_ferc1_eia = (\n",
    "    prettyify_best_matches(\n",
    "        matches_best, \n",
    "        plant_parts_true_df=inputs.plant_parts_true_df,\n",
    "        steam_df=inputs.all_plants_ferc1_df)\n",
    "    .copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c0a6a-73cf-41d5-a276-360679d5f7c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mul = (\n",
    "    make_plant_parts_eia.get_master_unit_list_eia(file_path_mul)\n",
    "    .reset_index()[relevant_cols_mul]\n",
    "    .copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a5b8aae-1d20-42e3-8f58-8e906d482e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the depreciation data from /Users/aesharpe/Desktop/Work/Catalyst_Coop/rmi-ferc1-eia/inputs/depreciation_rmi.xlsx\n",
      "# of reserve_rate over 1 (100%): 1. Higher #s here may indicate an issue with the original data or the fill_in method\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/aesharpe/Desktop/Work/Catalyst_Coop/rmi-ferc1-eia/outputs/common_assn.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c998252c6747>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name_deprish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     ).execute())\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdeprish_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m deprish_asset_df = agg_to_idx(\n\u001b[1;32m     10\u001b[0m     \u001b[0mdeprish_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Catalyst_Coop/rmi-ferc1-eia/src/pudl_rmi/deprish.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, clobber, agg_cols)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtidy_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_tidy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclobber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclobber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshaped_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclobber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclobber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;31m# value transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclobber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclobber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Catalyst_Coop/rmi-ferc1-eia/src/pudl_rmi/deprish.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(self, clobber)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclobber\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshaped_df\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;31m# common assn's: common id's w/ main id's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_assn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_common_assn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             data_cols = [\n",
      "\u001b[0;32m~/Desktop/Work/Catalyst_Coop/rmi-ferc1-eia/src/pudl_rmi/deprish.py\u001b[0m in \u001b[0;36mget_common_assn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;34m\"\"\"Get stored common plant assocations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0mpath_common_assn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'outputs/common_assn.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m     \u001b[0mcommon_assn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_common_assn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcommon_assn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pudl-dev/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pudl-dev/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pudl-dev/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pudl-dev/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pudl-dev/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pudl-dev/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pudl-dev/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/aesharpe/Desktop/Work/Catalyst_Coop/rmi-ferc1-eia/outputs/common_assn.csv'"
     ]
    }
   ],
   "source": [
    "file_path_deprish = pathlib.Path().cwd().parent/'inputs'/'depreciation_rmi.xlsx'\n",
    "sheet_name_deprish='Depreciation Studies Raw'\n",
    "transformer = pudl_rmi.deprish.Transformer(\n",
    "    pudl_rmi.deprish.Extractor(\n",
    "        file_path=file_path_deprish,\n",
    "        sheet_name=sheet_name_deprish\n",
    "    ).execute())\n",
    "deprish_df = transformer.execute()\n",
    "deprish_asset_df = agg_to_idx(\n",
    "    deprish_df,\n",
    "    idx_cols=[x for x in IDX_COLS_DEPRISH if x not in ['ferc_acct', 'note']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea42d47-995c-4b88-b082-24c87ea1be3a",
   "metadata": {},
   "source": [
    "### 1.2 Get the portion of FERC-EIA subject to review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe263a5-4c0a-439f-b031-48724c076f00",
   "metadata": {},
   "source": [
    "Here we'll limit the columns in the output file to those that will be useful for analysing match correctness. We'll also add some columns for you to use during the match verification process. All match types are included in the outputs (even those that have been correctly mapped according the current overrides) just incase there is a discrepancy or error that we want to fix.\n",
    "\n",
    "**Match Types:**\n",
    "\n",
    "* `prediction`: prediction based on the training data.\n",
    "* `correct_prediction`: prediction based on training data that matches record in the training data.\n",
    "* `no prediction; training`: not filled in by the prediction algorithm but filled in by the training data.\n",
    "* `overridden`: incorrectly filled in my prediction algorithm and corrected by training data.\n",
    "* `no_match`: a reviewer has found there to be no verified EIA match for the given FERC record.\n",
    "* `NaN`: not filled in by the training data or the prediction algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "ddd0b2d1-3538-4e5e-8152-4d22c42caf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                        33817\n",
       "prediction                 15140\n",
       "correct prediction           221\n",
       "no prediction; training       87\n",
       "overridden                    46\n",
       "Name: match_type, dtype: int64"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connects_ferc1_eia.match_type.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f780a96-8ea9-4504-ba42-a7c8bfe5f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the FERC-EIA connections that show the comparison between FERC and EIA values\n",
    "\n",
    "check_connections = (\n",
    "    connects_ferc1_eia[relevant_cols_ferc_eia].copy()\n",
    ")\n",
    "\n",
    "# Add a column to tell whether it's a good match, who verified / made the match,\n",
    "# and any notes about weirdness.\n",
    "check_connections.insert(0, \"is_correct_match\", np.nan)\n",
    "check_connections.insert(1, \"signature\", np.nan)\n",
    "check_connections.insert(2, \"notes\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145008b-4f9b-4420-bd42-d9f22d0adb21",
   "metadata": {},
   "source": [
    "### 1.3 Get and utility subsets for editing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcadb98-bd2f-41d9-b93d-d04ae3d309c6",
   "metadata": {},
   "source": [
    "Not sure which PUDL ID you need? Use this cell to search for them by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "e31b829f-c604-4cd9-af5d-3af6361cedd4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utility_id_pudl</th>\n",
       "      <th>utility_id_eia</th>\n",
       "      <th>utility_name_eia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2888</td>\n",
       "      <td>189</td>\n",
       "      <td>alabama electric coop inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>18</td>\n",
       "      <td>195</td>\n",
       "      <td>alabama power co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>4328</td>\n",
       "      <td>204</td>\n",
       "      <td>alabama pine pulp co inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>4330</td>\n",
       "      <td>349</td>\n",
       "      <td>alabama river pulp co inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45638</th>\n",
       "      <td>3423</td>\n",
       "      <td>18835</td>\n",
       "      <td>tenaska alabama ii partners, lp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55872</th>\n",
       "      <td>3424</td>\n",
       "      <td>31386</td>\n",
       "      <td>tenaska alabama partners lp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59431</th>\n",
       "      <td>428</td>\n",
       "      <td>40614</td>\n",
       "      <td>alabama municipal elec auth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75790</th>\n",
       "      <td>429</td>\n",
       "      <td>57356</td>\n",
       "      <td>alabama river cellulose llc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87778</th>\n",
       "      <td>6554</td>\n",
       "      <td>61964</td>\n",
       "      <td>kimberly clark - mobile alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       utility_id_pudl  utility_id_eia                 utility_name_eia\n",
       "529               2888             189        alabama electric coop inc\n",
       "573                 18             195                 alabama power co\n",
       "613               4328             204         alabama pine pulp co inc\n",
       "1097              4330             349        alabama river pulp co inc\n",
       "45638             3423           18835  tenaska alabama ii partners, lp\n",
       "55872             3424           31386      tenaska alabama partners lp\n",
       "59431              428           40614      alabama municipal elec auth\n",
       "75790              429           57356      alabama river cellulose llc\n",
       "87778             6554           61964  kimberly clark - mobile alabama"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util_name_string = 'alabama' # edit this, must be lower case\n",
    "\n",
    "utils = (\n",
    "    pudl_out.utils_eia860()[['utility_id_pudl', 'utility_id_eia', 'utility_name_eia']]\n",
    "    .drop_duplicates()\n",
    "    .dropna(subset=['utility_name_eia', 'utility_id_pudl'])\n",
    "    .assign(utility_name_eia=lambda x: x.utility_name_eia.str.lower())\n",
    ")\n",
    "utils[utils['utility_name_eia'].str.contains(f\"{util_name_string}\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba0a19-7a9d-48bc-beac-e11439b132a6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_inputs(check_connections_df, utilities='largest', amount=5, years='all'):\n",
    "    \n",
    "        all_plants_ferc1 = pudl_out.all_plants_ferc1().copy()\n",
    "        max_year = all_plants_ferc1.report_year.max()\n",
    "        min_year = all_plants_ferc1.report_year.min()\n",
    "\n",
    "        if years != 'all':\n",
    "            assert type(years) == list, \"years must be reported as a list if not 'all'\"\n",
    "            assert len([year for year in years if year in range(min_year, max_year)]) == len(years), \\\n",
    "                \"years must be 'all' or a valid year integer within the bounds of FERC reporting years\"\n",
    "        if years == 'all':\n",
    "            years = range(min_year, max_year+1)\n",
    "            \n",
    "        check_years = check_connections_df[check_connections_df['report_year'].isin(years)]\n",
    "        \n",
    "        if utilities == 'largest':\n",
    "            logger.info(f\"getting pudl ids for the top {amount} largest utilities\")\n",
    "            utilities = (\n",
    "                check_years\n",
    "                .groupby(['utility_id_pudl_eia', 'utility_name_ferc1'])['capacity_mw_ferc1']\n",
    "                .sum()\n",
    "                .reset_index()\n",
    "                .sort_values('capacity_mw_ferc1', ascending=False)\n",
    "                .head(amount)\n",
    "                .utility_id_pudl_eia\n",
    "                .tolist()\n",
    "            )\n",
    "        else:\n",
    "            assert type(utilities) == list, \"if not 'largest', utilities must be presented as a list of PUDL IDs\"\n",
    "            \n",
    "        return utilities, years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc8a28-45a7-4c8c-b81a-b73c18aaf85f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ferc_eia_utilities_subset(check_connections_df, utilities, years):\n",
    "    logger.info(\"retreiving the ferc-eia connection for the given utilities\")\n",
    "    check_years = check_connections_df[check_connections_df['report_year'].isin(years)]\n",
    "    util_output = check_years[check_years['utility_id_pudl_eia'].isin(utilities)].copy()\n",
    "    return util_output\n",
    "    \n",
    "def get_mul_subset(mul, utilities, years):\n",
    "    logger.info(\"retreiving the MUL for the given utilities\")\n",
    "    mul_years = mul[mul['report_year'].isin(years)]\n",
    "    mul_years[mul_years['utility_id_pudl'].isin(utilities)]\n",
    "    return mul_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a5417-5234-493b-8ae7-3b4862e18614",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def output_override_tools(check_connections_df, mul, utilities='largest', amount=5, years='all'):\n",
    "    \n",
    "    utilities, years = prep_inputs(check_connections_df, utilities, amount, years)\n",
    "    ferc_eia_util_subset = get_ferc_eia_utilities_subset(check_connections_df, utilities, years)\n",
    "    mul_util_subset = get_mul_subset(mul, utilities, years)\n",
    "    \n",
    "    # Create a dict of each df and the tab name you want to give it in the output\n",
    "    tool_dict = {\n",
    "        'ferc_eia_util_subset': ferc_eia_util_subset,\n",
    "        'mul_util_subset': mul_util_subset\n",
    "    }\n",
    "    \n",
    "    output_path = pathlib.Path().cwd().parent / 'outputs' / 'fix_FERC-EIA_overrides.xlsx'\n",
    "    \n",
    "    assert len(mul_util_subset) < 500000, \"Your MUL subset is more than 500,000 rows...this is going to make excel \\\n",
    "        reaaalllllyyy slow. Try entering a smaller utility or year subset\"\n",
    "    \n",
    "    logger.info(\"outputing files to csv\")\n",
    "    pudl_rmi.connect_deprish_to_eia.save_to_workbook(output_path, tool_dict)\n",
    "    \n",
    "    #return ferc_eia_util_subset, mul_util_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83bd814-1746-43e1-ac6c-45853143c6b9",
   "metadata": {},
   "source": [
    "## **Part 2:** Re-incorporating Matched Records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1ef398-6dec-4d3e-9e6a-ac850a39e6a7",
   "metadata": {},
   "source": [
    "Now that you've marked the correctly matched records as `TRUE`, we'll want to incorporate those into the perminant override list. All you have to do is move the `fix_FERC-EIA_overrides.xlsx` file to the `overrides` directory, run the following cells, and then run..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a5c89-fbe9-40bb-adf0-2eea59c82369",
   "metadata": {},
   "source": [
    "### 2.1 Update training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "226b40f3-9942-4254-938e-56f57c0584e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fixed_overrides_path = pathlib.Path().cwd().parent / 'overrides' #/ #'fix_FERC-EIA_overrides.xlsx'\n",
    "training_path = pathlib.Path().cwd().parent / 'inputs' / 'train_ferc1_to_eia.csv'\n",
    "\n",
    "# validated_connections = (\n",
    "#     pd.read_csv(ferc_eia_path)\n",
    "#     .assign(is_correct_match=lambda x: x.is_correct_match.replace({'TRUE':True, np.nan: False}))\n",
    "# )\n",
    "\n",
    "training_data = pd.read_csv(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c134c6b-d210-4665-99f2-5ae320532f08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_override_fixes(validated_connections, expect_override_overrides=False):\n",
    "    \"\"\"Process the verified / fixed matches.\"\"\"\n",
    "    \n",
    "    # Make sure that there are no rouge descriptions in the is_correct_match field (besides TRUE)\n",
    "    match_language = validated_connections.is_correct_match.unique()\n",
    "    assert len(outliers:=[x for x in match_language if x not in [True, False]]) == 0, \\\n",
    "        f\"All correct matches must be marked TRUE; found {outliers}\"\n",
    "\n",
    "    # Make it a boolean column\n",
    "    validated_connections.loc[:, \"is_correct_match\"] = (\n",
    "        validated_connections.is_correct_match.astype('bool'))\n",
    "\n",
    "    # Get TRUE records\n",
    "    true_connections = validated_connections[validated_connections['is_correct_match']].copy()\n",
    "\n",
    "    # Make sure that the eia and ferc ids haven't been tampered with\n",
    "    assert len(bad_eia := [x for x in true_connections.dropna().record_id_eia.unique()\n",
    "                        if x not in connects_ferc1_eia.record_id_eia.unique()]) == 0, \\\n",
    "        f\"Found record_id_eia values that aren't in the existing FERC-EIA connection: {bad_eia}\"\n",
    "    assert len(bad_ferc := [x for x in true_connections.dropna().record_id_ferc1.unique()\n",
    "                        if x not in connects_ferc1_eia.record_id_ferc1.unique()]) == 0, \\\n",
    "        f\"Found record_id_ferc1 values that aren't in the existing FERC-EIA connection: {bad_ferc}\"\n",
    "\n",
    "    if not expect_override_overrides:\n",
    "        # Make sure that these aren't already in the overrides (this should be impossible, but just in case)\n",
    "        assert len(bad_eia := [x for x in true_connections.record_id_eia.unique()\n",
    "                            if x in training_data.dropna(subset=['record_id_eia']).record_id_eia.unique()]) == 0,  \\\n",
    "            f\"Found record_id_eia values that are already in the existing FERC-EIA training data: {bad_eia}\"\n",
    "        assert len(bad_ferc := [x for x in true_connections.record_id_ferc1.unique()\n",
    "                            if x in training_data.dropna(subset=['record_id_eia']).record_id_ferc1.unique()]) == 0, \\\n",
    "            f\"Found record_id_ferc1 values that are already in the existing FERC-EIA training data: {bad_ferc}\"\n",
    "    \n",
    "    return true_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "639158dc-7fc7-4729-97cf-2c4fad13d875",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fixes in fix_FERC-EIA_overrides.xlsx\n",
      "Processing fixes in fix_FERC-EIA_overrides 2.xlsx\n"
     ]
    }
   ],
   "source": [
    "all_fixes = pd.DataFrame(columns=['record_id_eia', 'record_id_ferc1', 'signature', 'notes'])\n",
    "all_files = os.listdir(fixed_overrides_path)\n",
    "files = [file for file in all_files if not file.startswith('.')]\n",
    "for file in files:\n",
    "    assert (file.endswith('.xlsx'), 'fixing the overrides can only read .xslx \\\n",
    "        files; found other file types in the overrides directory')\n",
    "for file in files:\n",
    "    logger.info(f\"Processing fixes in {file}\")\n",
    "    file_df = (\n",
    "        pd.read_excel(\n",
    "            (fixed_overrides_path / file), \n",
    "            sheet_name='ferc_eia_util_subset')\n",
    "        .assign(is_correct_match=lambda x: (\n",
    "            x.is_correct_match.replace({'TRUE':True, np.nan: False})))\n",
    "        .pipe(validate_override_fixes, expect_override_overrides=expect_override_overrides))\n",
    "    all_fixes = all_fixes.append(file_df[['record_id_eia', 'record_id_ferc1',\n",
    "                                          'signature', 'notes']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d738d9c-8d33-45e0-a4dd-9f9ed9a1404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_out = (\n",
    "    training_data.append(\n",
    "        all_fixes[['record_id_eia', 'record_id_ferc1', 'signature', 'notes']])\n",
    "    .set_index(['record_id_eia', 'record_id_ferc1'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa73ed2-dfb1-47e8-bad7-14945b4944ae",
   "metadata": {},
   "source": [
    "### 2.2 Export updated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc225c-b4dd-4154-8b29-402d95ccc27a",
   "metadata": {},
   "source": [
    "Don't run this until you're ready! -- See top of the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
